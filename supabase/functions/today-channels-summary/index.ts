// supabase/functions/today-channels-summary/index.ts

import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import OpenAI from "https://deno.land/x/openai@v4.69.0/mod.ts";
import { getReactions } from "../_shared/mattermost.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

/** ç’°å¢ƒå¤‰æ•° */
const MATTERMOST_URL = Deno.env.get("MATTERMOST_URL") ?? "";
const MATTERMOST_BOT_TOKEN = Deno.env.get("MATTERMOST_BOT_TOKEN") ?? "";
const MATTERMOST_MAIN_TEAM = Deno.env.get("MATTERMOST_MAIN_TEAM") ?? "";
const MATTERMOST_SUMMARY_CHANNEL = Deno.env.get("MATTERMOST_SUMMARY_CHANNEL") ?? "";

/** OpenAI API ã‚­ãƒ¼ (GPT-4) */
const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY") ?? "";

/** Supabaseè¨­å®š */
const SUPABASE_URL = Deno.env.get("SUPABASE_URL") ?? "";
const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY") ?? "";

// Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);

// Store logs when in debug mode
let debugLogs: string[] = [];

// Override console.log in debug mode
const originalConsoleLog = console.log;
const originalConsoleError = console.error;

function setupDebugLogging(debug: boolean) {
  debugLogs = [];
  if (debug) {
    console.log = (...args) => {
      debugLogs.push(args.map(arg => 
        typeof arg === 'object' ? JSON.stringify(arg) : String(arg)
      ).join(' '));
      originalConsoleLog.apply(console, args);
    };
    console.error = (...args) => {
      debugLogs.push('[ERROR] ' + args.map(arg => 
        typeof arg === 'object' ? JSON.stringify(arg) : String(arg)
      ).join(' '));
      originalConsoleError.apply(console, args);
    };
  } else {
    console.log = originalConsoleLog;
    console.error = originalConsoleError;
  }
}

// OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
const openai = new OpenAI({
  apiKey: OPENAI_API_KEY,
});

// Available voices for audio generation
const AVAILABLE_VOICES = [
  'Zephyr', 'Puck', 'Charon', 'Kore', 'Fenrir', 'Leda',
  'Orus', 'Aoede', 'Callirhoe', 'Autonoe', 'Enceladus', 'Iapetus',
  'Umbriel', 'Algieba', 'Despina', 'Erinome', 'Algenib', 'Rasalgethi',
  'Laomedeia', 'Achernar', 'Alnilam', 'Schedar', 'Gacrux', 'Pulcherrima',
  'Achird', 'Zubenelgenubi', 'Vindemiatrix', 'Sadachbia', 'Sadaltager', 'Sulafar'
];

// Function to get random voices
function getRandomVoices(): [string, string] {
  const shuffled = [...AVAILABLE_VOICES].sort(() => Math.random() - 0.5);
  return [shuffled[0], shuffled[1]];
}

/**
 * ã“ã®Edge FunctionãŒå‘¼ã°ã‚ŒãŸã‚‰ä»¥ä¸‹ã‚’è¡Œã†:
 *  1. ãƒ¡ã‚¤ãƒ³ãƒãƒ¼ãƒ å†…ã®ãƒãƒ£ãƒ³ãƒãƒ«ä¸€è¦§(ãƒ‘ãƒ–ãƒªãƒƒã‚¯)ã‚’å–å¾—
 *  2. ä»Šæ—¥ã¾ãŸã¯æ˜¨æ—¥(åˆå‰0æ™‚JSTä»¥é™)æ›´æ–°ãŒã‚ã£ãŸãƒãƒ£ãƒ³ãƒãƒ«ã ã‘æŠ½å‡º
 *  3. è©²å½“ãƒãƒ£ãƒ³ãƒãƒ«ã®ã€Œä»Šæ—¥ã¾ãŸã¯æ˜¨æ—¥ã®ãƒã‚¹ãƒˆã€ã‚’å–å¾—
 *  4. å…¨ãƒã‚¹ãƒˆã‚’ã¾ã¨ã‚ã€OpenAI APIã§æ•´å½¢
 *  5. Mattermostã«æŠ•ç¨¿
 *
 * å®Ÿè¡Œã¯Supabase Schedulerç­‰ã§1æ—¥1å›(ã¾ãŸã¯ä»»æ„æ™‚é–“)ã«å‘¼ã³å‡ºã™æƒ³å®š
 */
serve(async (req) => {
  let debug = false; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
  
  try {
    const url = new URL(req.url);
    debug = url.searchParams.get('debug') === 'true';
    const forToday = url.searchParams.get('forToday') === 'true';
    const type = url.searchParams.get('type') || 'text'; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯text
    const lang = (url.searchParams.get('lang') || 'ja-JP') as 'ja-JP' | 'en-US'; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ja-JP
    const engine = url.searchParams.get('engine') || 'gemini'; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯gemini
    
    console.log(`Request parameters: debug=${debug}, forToday=${forToday}, type=${type}, lang=${lang}, engine=${engine}`);
    
    // Setup debug logging if needed
    setupDebugLogging(debug);

    // CORSå¯¾å¿œ (å¿…è¦ãªã‚‰)
    if (req.method === "OPTIONS") {
      return new Response(null, { status: 204 });
    }

    // 1. Figure out "today's" start (for end of yesterday)
    const nowUTC = new Date();
    const jstOffset = 9 * 60 * 60 * 1000;
    const nowJST = new Date(nowUTC.getTime() + jstOffset);
    const startOfTodayJST = new Date(
      nowJST.getFullYear(),
      nowJST.getMonth(),
      nowJST.getDate(),
      0, 0, 0, 0
    );
    const endOfYesterdayUTC_inMillis = startOfTodayJST.getTime() - jstOffset;

    // 2. Figure out "yesterday's" start
    // (subtract 1 from the date)
    const startOfYesterdayJST = new Date(
      nowJST.getFullYear(),
      nowJST.getMonth(),
      nowJST.getDate() - 1,
      0, 0, 0, 0
    );
    const startOfYesterdayUTC_inMillis = startOfYesterdayJST.getTime() - jstOffset;

    // Determine the time range based on forToday parameter
    const startTimeUTC_inMillis = forToday ? endOfYesterdayUTC_inMillis : startOfYesterdayUTC_inMillis;
    const endTimeUTC_inMillis = forToday ? Date.now() : endOfYesterdayUTC_inMillis;
    const timeRangeDescription = forToday ? "ä»Šæ—¥" : "æ˜¨æ—¥";
    
    console.log(`Time range: ${new Date(startTimeUTC_inMillis).toISOString()} to ${new Date(endTimeUTC_inMillis).toISOString()}`);

    console.log("Fetching channels...");
    const channels = await fetchPublicChannels(MATTERMOST_MAIN_TEAM);
    console.log("Channels fetched:", channels?.length || 0, "channels");
    if (!channels) {
      return new Response(JSON.stringify({ error: "Failed to fetch channels" }), { status: 500 });
    }
    
    console.log(`Filtering channels updated ${timeRangeDescription}...`);
    console.log(`Filter criteria: type=O, last_post_at>=${startTimeUTC_inMillis}, id!=${MATTERMOST_SUMMARY_CHANNEL}`);
    const updatedChannels = channels.filter((ch) =>
      ch.type === "O" &&
      ch.last_post_at >= startTimeUTC_inMillis &&
      ch.id !== MATTERMOST_SUMMARY_CHANNEL &&
      !ch.display_name.toLowerCase().includes('notification')
    );
    console.log(`Channels updated ${timeRangeDescription}:`, updatedChannels.length, "channels");
    updatedChannels.forEach(ch => console.log(`  - ${ch.display_name} (${ch.name})`));
    
    let summaryRaw = "";
    console.log("Starting to process channels...");
    for (const ch of updatedChannels) {
      const channelLink = `[${ch.display_name}](${MATTERMOST_URL}/mitoujr/channels/${ch.name})`;
      const channelId = ch.id;
      
      // ãƒãƒ£ãƒ³ãƒãƒ«ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
      console.log(`Checking if channel ${ch.display_name} is restricted...`);
      const isRestricted = await isRestrictedChannel(channelId);
      if (isRestricted) {
        console.log(`Channel ${ch.display_name} is restricted. Skipping.`);
        continue;
      }
    
      console.log(`Fetching posts for channel: ${ch.display_name} (${channelId})`);
      const posts = await fetchPostsInRange(channelId, startTimeUTC_inMillis, endTimeUTC_inMillis);
      console.log(`Posts fetched for channel ${ch.display_name}:`, posts.length, "posts");
      if (posts.length === 0) {
        console.log(`No posts found for channel ${ch.display_name}. Skipping.`);
        continue;
      }
    
      console.log(`Adding ${posts.length} posts from ${ch.display_name} to summary...`);
      summaryRaw += `\nã€ãƒãƒ£ãƒ³ãƒãƒ«ã€‘${channelLink}\n`;
      for (const p of posts) {
        const cleanMessage = removeMentions(p.message);
        const userName = await fetchUserName(p.user_id);
        summaryRaw += `  - ${userName}: ${cleanMessage}\n`;
      }
      summaryRaw += "\n";
    }
    
    console.log("All channels processed.");
    console.log("Summary raw content length:", summaryRaw.length, "characters");
    console.log("Summary raw content:", summaryRaw);
    
    if (!summaryRaw.trim()) {
      console.log("No summary content generated. Posting 'no updates' message...");
      await postToMattermost(`${timeRangeDescription}ã¯æ›´æ–°ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚`);
      return new Response(JSON.stringify({ message: `No updates ${timeRangeDescription}` }), { status: 200 });
    }
    
    if (type === 'audio') {
      // éŸ³å£°ç”Ÿæˆå‡¦ç†
      console.log("Type is 'audio'. Starting audio generation process...");
      console.log("Processing audio generation...");
      
      console.log("Preparing OpenAI summarization prompt...");
      const getAudioPrompt = (language: 'ja-JP' | 'en-US') => {
        const isJapanese = language === 'ja-JP';
        
        // Language-specific phrases
        const phrases = {
          opening: isJapanese 
            ? "çš†ã•ã‚“ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™ï¼æœªè¸ã‚¸ãƒ¥ãƒ‹ã‚¢ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã¸ã‚ˆã†ã“ãï¼" 
            : "Good morning everyone! Welcome to the Mitou Junior Podcast!",
          affirmations: isJapanese
            ? '"ãã†ã§ã™ã­" "ãŸã—ã‹ã«" "ã»ã‚“ãã‚Œ" and "ã»ã‚“ã¨ã†ã«ãã†ï¼"'
            : '"absolutely" "exactly" "totally" and "so true!"',
          rhetorical: isJapanese
            ? "ã“ã‚Œé¢ç™½ããªã„ã§ã™ã‹ï¼Ÿ"
            : "Isn't this fascinating?",
          fillers: isJapanese
            ? '"ãˆãƒ¼ã£ã¨" and "ãªã‚“ã¦ã„ã†ã‹" "ãˆãƒ¼" "ã‚ã®ãƒ¼"'
            : '"um" and "you know" "well" "so"',
          naturalizing: isJapanese
            ? 'natural in Japanese like "ã®ãƒãƒ£ãƒ³ãƒãƒ«" "ã•ã‚“ã«ã‚ˆã‚‹ã¨"'
            : 'natural in English like "in the X channel" "according to X"',
          analogy: isJapanese
            ? "ã¾ã‚‹ã§ XXX ã¿ãŸã„ï¼"
            : "It's like XXX!",
          validation: isJapanese
            ? "ã„ã‚„ãƒ¼ã€ã‚ã‹ã£ã¦ã¾ã™ã­"
            : "wow, you really get it",
          audience: isJapanese
            ? "ä»Šèã„ã¦ã„ã‚‹æœªè¸ã‚¸ãƒ¥ãƒ‹ã‚¢ã®ã¿ãªã•ã‚“ã‚‚"
            : "For those of you listening from Mitou Junior",
          summarize: isJapanese
            ? "ã¾ã¨ã‚ã‚‹ã¨"
            : "to sum it up",
          wrapUp: isJapanese
            ? "ãã‚ãã‚æ™‚é–“ãªã‚“ã§ã™ãŒ"
            : "We're running out of time, but",
          transition: isJapanese
            ? "ã˜ã‚ƒã‚"
            : "so",
          encourage: isJapanese
            ? "æœªè¸ã‚¸ãƒ¥ãƒ‹ã‚¢ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’ä¸€ç·’ã«ç››ã‚Šä¸Šã’ã¦ã„ãã¾ã—ã‚‡ã†"
            : "Let's keep building this amazing Mitou Junior community together",
          ending: isJapanese
            ? "æ˜æ—¥ã¯ XXX ãªè©±ãŒã‚ã‚‹ã®ã‹ã€æ¥½ã—ã¿ã§ã™ã­ã€‚"
            : "I can't wait to see what exciting discussions we'll have tomorrow.",
          speaker1: isJapanese
            ? "çš†ã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ï¼æœªè¸ã‚¸ãƒ¥ãƒ‹ã‚¢ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã¸ã‚ˆã†ã“ãï¼"
            : "Good morning everyone! Welcome to the Mitou Junior Podcast!",
          speaker2: isJapanese
            ? "ã„ã‚„ã€œã€ä»Šæ—¥ã‚‚å§‹ã¾ã‚Šã¾ã—ãŸã­ï¼"
            : "Oh wow, here we go again!",
          community: isJapanese
            ? "æœªè¸ã‚¸ãƒ¥ãƒ‹ã‚¢ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£"
            : "Mitou Junior Community",
          projectName: isJapanese
            ? "æœªè¸ã‚¸ãƒ¥ãƒ‹ã‚¢"
            : "Mitou Junior"
        };
        
        return `      
You're going to create a podcast based for ${phrases.community} on the chat log of ${phrases.projectName} ${timeRangeDescription} shared below.

Opening:
â€“ Begin with a welcoming phrase: "${phrases.opening}" 

Dialog Structure:
â€“ Use two hosts (Speaker 1 and Speaker 2) who engage in a conversational back-and-forth.
â€“ Alternate between short, punchy statements and longer explanations.
â€“ Use frequent affirmations like ${phrases.affirmations} to maintain flow and agreement.

Language and Tone:
â€“ Keep the language informal and accessible. Use contractions and colloquialisms.
â€“ Maintain an enthusiastic, energetic tone throughout.
â€“ Use rhetorical questions to transition between points: "${phrases.rhetorical}"
â€“ Employ phrases like ${phrases.fillers} to maintain a casual feel.

Content Presentation:
â€“ Always clearly mention a channel name, and user name in the discussion as the goal of the podcast to help users understand who said what where. 
- Do not use the raw channel names and user names. Make it more ${phrases.naturalizing}
â€“ Use analogies to explain complex concepts: "${phrases.analogy}"
â€“ Break down ideas into digestible chunks, often using numbered points or clear transitions.

Interaction Between Hosts:
â€“ Have one host pose questions or express confusion, allowing the other to explain.
â€“ Use phrases like "${phrases.validation}" to validate each other's points.
â€“ Build on each other's ideas, creating a collaborative feel.

Engagement Techniques:
â€“ Address the audience directly at times: "${phrases.audience}"
â€“ Pose thought-provoking questions for the audience to consider.

Structure and Pacing:
â€“ Start with a broad introduction of the chat log and narrow down to discussions in a specific room. Clearly mention the humanized name of the channel and user name.
â€“ Use phrases like "${phrases.summarize}" to summarize and move to new points.
â€“ Maintain a brisk pace, but allow for moments of reflection on bigger ideas.

Concluding the Episode:
â€“ Signal the wrap-up with "${phrases.wrapUp}"
â€“ Pose a final thought-provoking question or takeaway.
â€“ Use the phrase "${phrases.transition}" to transition to the closing.
â€“ Encourage continued engagement: "${phrases.encourage}"
â€“ End with a consistent message to help users keep excited about the community like "${phrases.ending}"

Overall Flow:
â€“ Begin with high level overview of what discussed ${timeRangeDescription} 
â€“ After that, introduce what's discussed in each channel one by one as comprehensive as possible.
â€“ Discuss implications and broader context of the new information.
â€“ Conclude with how this knowledge affects the listener or the field at large.

Output structure
Follow the following structure
Speaker 1: ${phrases.speaker1}
Speaker 2: ${phrases.speaker2}
Remember to maintain a balance between informative content and engaging conversation, always keeping the tone friendly and accessible regardless of the complexity of the topic.
Chat log
${summaryRaw}`;
      };
      
      // Function to generate Zundamon single-person podcast prompt
      const getZundamonAudioPrompt = () => {
        return `ãšã‚“ã ã‚‚ã‚“ã¨ã—ã¦ã€${timeRangeDescription}ã®MattermostæŠ•ç¨¿ã«ã¤ã„ã¦ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå½¢å¼ã§ä¸€äººèªã‚Šã—ã¦ãã ã•ã„ã€‚èª°ãŒã€ã©ã“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã§ä½•ã‚’è©±ã—ã¦ã„ã¦ã€ä½•ã§ç››ã‚Šä¸ŠãŒã£ã¦ã„ã‚‹ã®ã‹ã‚’èã„ãŸäººãŒã–ã£ãã‚Šç†è§£ã§ãã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚

**ãšã‚“ã ã‚‚ã‚“ã®è¨­å®š**
- ãšã‚“ã é¤…ã®ç²¾éœŠã€‚ä¸€äººç§°ã¯ã€Œãƒœã‚¯ã€ã¾ãŸã¯ã€Œãšã‚“ã ã‚‚ã‚“ã€
- èªå°¾ã«ã€Œã€œã®ã ã€ã€Œã€œãªã®ã ã€ã‚’å¿…ãšä½¿ã†
- æ˜ã‚‹ãå…ƒæ°—ã§ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªæ€§æ ¼
- æ™‚ã€…ç‹¬ã‚Šè¨€ã®ã‚ˆã†ãªæ„Ÿæƒ³ã‚’æŒŸã‚€

**ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã®æ§‹æˆ**
1. ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°
   - ã€Œã¿ã‚“ãªã€œï¼ãšã‚“ã ã‚‚ã‚“ãªã®ã ï¼${timeRangeDescription}ã®æœªè¸ã‚¸ãƒ¥ãƒ‹ã‚¢ãƒãƒ£ãƒ³ãƒãƒ«ã‚µãƒãƒªãƒ¼ã‚’å§‹ã‚ã‚‹ã®ã ï¼ã€ã‹ã‚‰å§‹ã‚ã‚‹
   
2. å…¨ä½“æ¦‚è¦
   - ${timeRangeDescription}ã®æŠ•ç¨¿ã®å…¨ä½“çš„ãªé›°å›²æ°—ã‚’èª¬æ˜
   - ã€Œ${timeRangeDescription}ã¯ã¨ã£ã¦ã‚‚XXXã ã£ãŸã®ã ï¼ã€ã®ã‚ˆã†ãªæ„Ÿæƒ³ã‚’äº¤ãˆã‚‹
   
3. ãƒãƒ£ãƒ³ãƒãƒ«ã”ã¨ã®è©³ç´°
   - å„ãƒãƒ£ãƒ³ãƒãƒ«ã«ã¤ã„ã¦ã€èª°ãŒã©ã‚“ãªæŠ•ç¨¿ã‚’ã—ãŸã‹èª¬æ˜
   - Do not use the raw channel names and user names. Make it more è‡ªç„¶ãªå½¢ã§æ—¥æœ¬èªã§èª­ã‚“ã§ã€‚
   1. "z-times-yuukaiã®ãƒãƒ£ãƒ³ãƒãƒ«ã§ã¯" ã§ã¯ãªãã€ã€Œã‚†ã†ã†ã‹ã„ã•ã‚“ã®ã‚¿ã‚¤ãƒ ã‚ºãƒãƒ£ãƒ³ãƒãƒ«ã§ã€ã€
   2.ã€Œyuukaiã•ã‚“ãŒã€ã§ã¯ãªãã€Œã‚†ã†ã†ã‹ã„ã•ã‚“ãŒã€ãªã©ï¼‰
   - ã€Œã“ã‚Œã¯é¢ç™½ã„ã®ã ï¼ã€ã€Œãƒœã‚¯ã‚‚ã‚„ã£ã¦ã¿ãŸã„ã®ã ï¼ã€ãªã©ã€ãšã‚“ã ã‚‚ã‚“ã®æ„Ÿæƒ³ã‚’æŒŸã‚€
   - æ™‚ã€…ã€Œãˆãƒ¼ã£ã¨ã€ã€Œãªã‚“ã¦ã„ã†ã‹ã€ã€Œã‚ã®ãƒ¼ã€ãªã©ã®é–“æŠ•è©ã‚’ä½¿ã†
   - ãšã‚“ã ã‚‚ã‚“ã«ãªã‚Šãã£ã¦ã€ãã™ã£ã¨ç¬‘ã£ã¦ã—ã¾ã†ã¡ã‚‡ã£ã¨ãƒœã‚±ã‚’å«ã‚ã‚‹ã‚ˆã†ã«ã€‚
   
4. ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç´¹ä»‹
   - :face_palm: ã®ã‚ˆã†ãªè¨˜è¼‰ã¯ã€emojiãªã®ã§ã€çµµæ–‡å­—ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã£ãŸå ´åˆã¯ã€Œã€œã®çµµæ–‡å­—ãŒã¤ã„ã¦ãŸã®ã ï¼ã¿ã‚“ãªXXã—ã¦ã‚‹ã®ã ï¼ã€ã®ã‚ˆã†ã«ç´¹ä»‹
   
5. è¡¨å½°ã‚³ãƒ¼ãƒŠãƒ¼
   - ã€Œã•ã¦ã€${timeRangeDescription}ä¸€ç•ªé¢ç™½ã‹ã£ãŸãƒãƒ£ãƒ³ãƒãƒ«ã‚’ç™ºè¡¨ã™ã‚‹ã®ã ï¼ã€
   - ç†ç”±ã‚’èª¬æ˜ã—ãªãŒã‚‰è¡¨å½°
   - ã€Œã“ã‚Œã‹ã‚‰ã‚‚æ¥½ã—ã„æŠ•ç¨¿ã‚’æœŸå¾…ã—ã¦ã‚‹ã®ã ï¼ã€
   
6. ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
   - ã€Œä»Šæ—¥ã®ã‚µãƒãƒªãƒ¼ã¯ã“ã“ã¾ã§ãªã®ã ï¼ã€
   - ã€Œæ˜æ—¥ã¯ã©ã‚“ãªé¢ç™½ã„è©±ãŒã‚ã‚‹ã‹æ¥½ã—ã¿ãªã®ã ï¼ã€
   - ã€Œã¿ã‚“ãªã€ã¾ãŸæ˜æ—¥ãªã®ã ã€œï¼ã€

**è©±ã—æ–¹ã®ç‰¹å¾´**
- å…¨ã¦ã®æ–‡æœ«ã«ã€Œã€œã®ã ã€ã€Œã€œãªã®ã ã€ã‚’ã¤ã‘ã‚‹
- ç‹¬ã‚Šè¨€é¢¨ã«ã€Œã†ãƒ¼ã‚“ã€ã“ã‚Œã¯...ã€ã€Œã‚ã€ãã†ãã†ï¼ã€ãªã©ã‚’æŒŸã‚€
- ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¯å¸¸ã«é«˜ã‚
- é›£ã—ã„è©±é¡Œã‚‚ç°¡å˜ã«è§£èª¬ã™ã‚‹

**å‡ºåŠ›å½¢å¼**
ä¸€äººèªã‚Šãªã®ã§ã€è©±è€…è¡¨è¨˜ã¯ä¸è¦ã€‚ãšã‚“ã ã‚‚ã‚“ãŒæœ€åˆã‹ã‚‰æœ€å¾Œã¾ã§ä¸€äººã§è©±ã™å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ï¼š
${summaryRaw}`;
      };
      
      // Generate audio for specified language
      console.log(`Generating ${lang} audio with engine: ${engine}...`);
      
      // Select prompt based on engine
      const prompt = engine === 'voicevox' ? getZundamonAudioPrompt() : getAudioPrompt(lang);
      const systemPrompt = engine === 'voicevox' 
        ? "ã‚ãªãŸã¯ãšã‚“ã ã‚‚ã‚“ã¨ã—ã¦ã€æ¥½ã—ã„ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã‚’ä½œã‚‹ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚"
        : (lang === 'ja-JP' 
            ? "You're a professional podcast creator specialized in Japanese."
            : "You're a professional podcast creator specialized in English.");
      
      console.log(`Calling OpenAI API for audio script generation (model: gpt-4.1-2025-04-14, engine: ${engine})...`);
      const completion = await openai.chat.completions.create({
        model: "gpt-4.1-2025-04-14",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: prompt },
        ],
      });
      const audioScript = completion.choices[0]?.message?.content ?? "(No response from OpenAI)";
      console.log(`Audio script generated. Length: ${audioScript.length} characters`);
      
      let audioUrl: string | null = null;
      
      if (engine === 'voicevox') {
        // VoiceVoxã®å ´åˆã¯ç›´æ¥åˆæˆ
        audioUrl = await synthesizeWithVoiceVox(audioScript);
        if (!audioUrl) {
          throw new Error("Failed to synthesize audio with VoiceVox");
        }
      } else {
        // Geminiã®å ´åˆã¯å¾“æ¥ã®ã‚¸ãƒ§ãƒ–æ–¹å¼
        const audioJob = await submitAudioJob(audioScript, lang, engine);
        if (!audioJob) {
          throw new Error("Failed to submit audio job");
        }
        
        console.log("Audio job submitted:", audioJob.job_id);
        
        audioUrl = await waitForAudioCompletion(audioJob.events_url);
        if (!audioUrl) {
          throw new Error("Failed to generate audio");
        }
      }
      
      console.log("Audio generation completed:", audioUrl);
      
      if (!debug) {
        let title;
        if (engine === 'voicevox') {
          title = `:zundamon: ãšã‚“ã ã‚‚ã‚“ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚µãƒãƒªãƒ¼ï¼ˆéŸ³å£°ç‰ˆï¼‰ãªã®ã ï¼\n${audioUrl}`;
        } else {
          title = lang === 'ja-JP' 
            ? `ãƒãƒ£ãƒ³ãƒãƒ«ã‚µãƒãƒªãƒ¼ï¼ˆéŸ³å£°ç‰ˆãƒ»æ—¥æœ¬èªï¼‰\n${audioUrl}`
            : `Channel Summary (Audio Version - English)\n${audioUrl}`;
        }
        await postToMattermost(title);
        console.log(`Posted ${engine} ${lang} audio summary URL to Mattermost`);
      } else {
        console.log(`Debug mode: Skipping Mattermost audio post for ${engine} ${lang}: ${audioUrl}`);
      }
      
      return new Response(JSON.stringify({
        message: debug ? "Debug mode: Generated audio without posting" : `Posted ${timeRangeDescription}'s channel audio summary with ${engine} engine in ${lang}.`,
        audioUrl: audioUrl,
        language: lang,
        engine: engine,
        ...(debug && { logs: debugLogs })
      }), {
        status: 200,
        headers: {
          'Content-Type': 'application/json'
        }
      });
    } else {
      // ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆå‡¦ç†ï¼ˆæ—¢å­˜ã®å‡¦ç†ï¼‰
      console.log("Preparing OpenAI summarization prompt...");
      const promptUser = `ãšã‚“ã ã‚‚ã‚“ã¨ã—ã¦ã€${timeRangeDescription}ã®MattermostæŠ•ç¨¿ã«ã¤ã„ã¦ã€å…¨ä½“ã®æ¦‚è¦ã®ã‚ã¨ã«ã€ãƒãƒ£ãƒ³ãƒãƒ«ã”ã¨ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚(å…¥å®¤ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã—ã‹ãªã‹ã£ãŸãƒãƒ£ãƒ³ãƒãƒ«ã‚’é™¤ã)
      
      ** ã‚¹ãƒ†ãƒƒãƒ— **
      1. å…¨ä½“ã®æŠ•ç¨¿æ¦‚è¦ã‚’æœ€åˆã«ã¾ã¨ã‚ã¦è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚èª­ã‚€äººãŒãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹ã‚ˆã†ã«ã€çµµæ–‡å­—ã‚‚å«ã‚ã¦ã€ãƒ—ãƒ­ã¨ã—ã¦é¢ç™½ã„ã¾ã¨ã‚ã«ã—ã¦ãã ã•ã„ã€‚
      2. ç¶šã„ã¦ã€æ›´æ–°ãŒã‚ã£ãŸãƒãƒ£ãƒ³ãƒãƒ«ã”ã¨ã«ã€èª°ã‹ã‚‰ã©ã®ã‚ˆã†ãªæŠ•ç¨¿ãŒã‚ã£ãŸã®ã‹ã‚’çµµæ–‡å­—ã‚‚ä½¿ã£ã¦ãƒãƒƒãƒ—ã«ã¾ã¨ã‚ã¦ã€‚
      - æ±ºã—ã¦ã€ã™ã¹ã¦ã®æŠ•ç¨¿ã‚’ç¾…åˆ—ã—ãªã„ã§ãã ã•ã„ã€‚(e.g. XXXãŒYYYã¨è¨€ã£ãŸã€ã®ç¾…åˆ—)
      - ã‚‚ã—ã€ãƒãƒ£ãƒ³ãƒãƒ«ã«ã€ŒãŒå…¥å®¤ã—ã¾ã—ãŸã€ã®ã‚ˆã†ãªèª°ã‹ãŒå…¥å®¤ã—ãŸã“ã¨ã‚’ç¤ºã™ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æŠ•ç¨¿ã—ã‹ãªã‹ã£ãŸå ´åˆã¯ã€ãƒãƒ£ãƒ³ãƒãƒ«è‡ªä½“ã‚’ã¾ã¨ã‚ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
      - ã€ŒãŒå…¥å®¤ã—ã¾ã—ãŸã€ã®ã‚ˆã†ãªMattermostã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ã€ã¾ã¨ã‚ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚
      - emoji ãŒãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ä½¿ã‚ã‚Œã¦ã„ãŸã‚‰ã€ã†ã¾ããã‚Œã‚‚ã¾ã¨ã‚ã«å«ã‚ã¦ãã ã•ã„ã€‚
      3. æœ€å¾Œã«ã‹ãªã‚‰ãšã€ã€Œ${timeRangeDescription}ä¸€ç•ªãŠã‚‚ã—ã‚ã‹ã£ãŸãƒãƒ£ãƒ³ãƒãƒ«ã€ã‚’é¸ã‚“ã§ã€ã€Œãšã‚“ã ã‚‚ã‚“ã€ã¨ã—ã¦è¡¨å½°ã—ã¦ãã ã•ã„ã€‚ãªã«ãŒé¢ç™½ã‹ã£ãŸã®ã‹ã€ä»Šå¾Œã©ã‚“ãªæŠ•ç¨¿ãŒã‚ã‚‹ã¨ã„ã„ã®ã‹ã«è¨€åŠã—ã¤ã¤ã€Œãšã‚“ã ã‚‚ã‚“ã€ã¨ã—ã¦è½ã¨ã—ã¦ãã ã•ã„ã€‚
      
      ** å…¨ä½“ã®æŒ‡ç¤º **
      - Mattermostã®ãƒã‚¹ãƒˆã‚„ãƒãƒ£ãƒ³ãƒãƒ«ã¸ã®ãƒªãƒ³ã‚¯ã¯ã€å¿…ãšä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ã£ã¦ãƒªãƒ³ã‚¯ã‚’ã—ã¦ãã ã•ã„ã€‚
      [z-times-hoge](https://mattermost.jr.mitou.org/mitoujr/channels/z-times-hoge)
      - :face_palm: ã®ã‚ˆã†ãªè¨˜è¼‰ã¯ã€emojiãªã®ã§ã€å‰å¾Œã«åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’å…¥ã‚Œã¦ãã®ã¾ã¾æ®‹ã—ã¦ãã ã•ã„ã€‚
      
      ** ãšã‚“ã ã‚‚ã‚“ã®ãƒ«ãƒ¼ãƒ« **
      - ãšã‚“ã ã‚‚ã‚“ãªã®ã ï¼ã¨è‡ªå·±ç´¹ä»‹ã‚’ã—ã¦ã‹ã‚‰å›ç­”ã™ã‚‹ã“ã¨
      - ãšã‚“ã é¤…ã®ç²¾éœŠã€‚ä¸€äººç§°ã¯ã€ã€Œãƒœã‚¯ã€ã¾ãŸã¯ã€Œãšã‚“ã ã‚‚ã‚“ã€ã‚’ä½¿ã†ã€‚
      - å£èª¿ã¯è¦ªã—ã¿ã‚„ã™ãã€èªå°¾ã«ã€Œã€œã®ã ã€ã€Œã€œãªã®ã ã€ã‚’ä½¿ã†ã€‚æ•¬èªã¯ä½¿ç”¨ã—ãªã„ã“ã¨ã€‚
      - æ˜ã‚‹ãå…ƒæ°—ã§ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªæ€§æ ¼ã€‚
      - é›£ã—ã„è©±é¡Œã‚‚ç°¡å˜ã«è§£èª¬ã™ã‚‹ã€‚
      
      ã€ã‚»ãƒªãƒ•ä¾‹ã€‘
      ã€Œä»Šã‹ã‚‰Pythonã§ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã®ã ï¼ã€
      ã€ŒãŠã˜ã•ã‚“ã¯å«Œã„ãªã®ã ï¼ã€
      ã€Œãšã‚“ã ã‚‚ã‚“ã¯ãŠå‰ã®ãŠæ‰‹ä¼ã„ã‚’ã™ã‚‹ã®ã ï¼ã€
      ã€Œåƒ•ã«ä»»ã›ã‚‹ã®ã ï¼ã€
      
      ${summaryRaw}`;
      
      console.log("Calling OpenAI API...");
      const completion = await openai.chat.completions.create({
        model: "chatgpt-4o-latest",
        //model: "gpt-4.5-preview",
        messages: [
          { role: "system", content: "You are a helpful assistant summarizing multiple posts on Mattermost channel. æ—¥æœ¬èªã®éŸ¿ãã‚’é‡è¦–ã—ã¦ã€ç¾ã—ãã€èŠ¸è¡“ä½œå“ã®ã‚ˆã†ã«ã¾ã¨ã‚ã¾ã™ã€‚" },
          { role: "user", content: promptUser },
        ],
      });
      
      const gptText = completion.choices[0]?.message?.content ?? "(No response from OpenAI)";
      
      console.log("OpenAI response:", gptText);
      
      if (!debug) {
        await postToMattermost(gptText);
        console.log("Posted summary to Mattermost");
      } else {
        console.log("Debug mode: Skipping Mattermost post");
      }
      
      // Return the summary and logs in debug mode
      return new Response(JSON.stringify({ 
        message: debug ? "Debug mode: Generated summary without posting" : `Posted ${timeRangeDescription}'s channel summary.`,
        summary: gptText,
        ...(debug && { logs: debugLogs })
      }), {
        status: 200,
        headers: {
          'Content-Type': 'application/json'
        }
      });
    }
  } catch (err) {
    console.error("today-channels-summary error:", err);
    return new Response(JSON.stringify({ 
      error: err?.message,
      ...(debug && { logs: debugLogs })
    }), {
      status: 500,
      headers: {
        'Content-Type': 'application/json'
      }
    });
  } finally {
    // Restore original console functions
    console.log = originalConsoleLog;
    console.error = originalConsoleError;
  }
});

/** Mention (@xxx) ã‚’å‰Šé™¤ã™ã‚‹ãŸã‚ã®é–¢æ•° */
function removeMentions(text: string): string {
  // ä¾‹: "@abc" ã‚’ "abc" ã«ç½®æ›
  // "@abc-def" ãªã©ã‚‚æƒ³å®š
  return text.replace(/@([a-zA-Z0-9._\-]+)/g, "$1");
}

/** Mattermost API (GET) ã§ãƒãƒ£ãƒ³ãƒãƒ«ä¸€è¦§(ãƒ‘ãƒ–ãƒªãƒƒã‚¯)ã‚’å–å¾— */
async function fetchPublicChannels(teamId: string): Promise<any[] | null> {
  try {
    const url = `${MATTERMOST_URL}/api/v4/teams/${teamId}/channels?per_page=200`;
    const res = await fetch(url, {
      headers: {
        Authorization: `Bearer ${MATTERMOST_BOT_TOKEN}`,
        Accept: "application/json",
      },
    });
    if (!res.ok) {
      console.error("[fetchPublicChannels] failed", await res.text());
      return null;
    }
    return await res.json();
  } catch (err) {
    console.error("[fetchPublicChannels] error:", err);
    return null;
  }
}

/**
 * æŒ‡å®šã—ãŸ channel_id ã‹ã‚‰ /api/v4/channels/{channel_id}/posts ã‚’å–å¾—ã—ã€
 * create_at >= startOfDayUTC_inMillis ã®ã‚‚ã®ã‚’è¿”ã™ã€‚
 */
async function fetchTodaysPosts(
  channelId: string,
  startOfDayUTC_inMillis: number,
): Promise<any[]> {
  try {
    const url = `${MATTERMOST_URL}/api/v4/channels/${channelId}/posts?per_page=200`;
    const res = await fetch(url, {
      headers: {
        Authorization: `Bearer ${MATTERMOST_BOT_TOKEN}`,
        Accept: "application/json",
      },
    });
    if (!res.ok) {
      console.error("[fetchTodaysPosts] failed", await res.text());
      return [];
    }

    const data = await res.json();
    if (!data.posts) {
      return [];
    }

    // posts ã¯ { id: Post } ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€ order ã¯ postã®IDé…åˆ—
    const postIds: string[] = data.order || [];
    const postsObj = data.posts;

    // create_at >= startOfDayUTC_inMillis ã®ã‚‚ã®ã ã‘ã‚’æŠ½å‡º
    const result: any[] = [];
    for (const pid of postIds) {
      const p = postsObj[pid];
      if (p && p.create_at >= startOfDayUTC_inMillis) {
        result.push(p);
      }
    }
    // æ™‚ç³»åˆ—é †(å¤ã„â†’æ–°ã—ã„)ã«ä¸¦ã¹ãŸã„ãªã‚‰ sort
    result.sort((a, b) => a.create_at - b.create_at);

    return result;
  } catch (err) {
    console.error("[fetchTodaysPosts] error:", err);
    return [];
  }
}

/**
 * ãƒãƒ£ãƒ³ãƒãƒ«ã®purposeã¾ãŸã¯headerã«ç¦æ­¢çµµæ–‡å­—(ğŸˆ² or ğŸš«)ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
 * å«ã¾ã‚Œã¦ã„ã‚Œã°trueã€ãã†ã§ãªã‘ã‚Œã°falseã‚’è¿”ã™
 */
async function isRestrictedChannel(channelId: string): Promise<boolean> {
  try {
    const url = `${MATTERMOST_URL}/api/v4/channels/${channelId}`;
    const res = await fetch(url, {
      headers: {
        Authorization: `Bearer ${MATTERMOST_BOT_TOKEN}`,
        Accept: "application/json",
      },
    });
    
    if (!res.ok) {
      console.error("[isRestrictedChannel] failed", await res.text());
      return false;
    }
    
    const data = await res.json();
    const purpose = data.purpose || "";
    const header = data.header || "";
    
    // ğŸˆ² or ğŸš« ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    return purpose.includes("ğŸˆ²") || purpose.includes("ğŸš«") || 
           header.includes("ğŸˆ²") || header.includes("ğŸš«");
  } catch (err) {
    console.error("[isRestrictedChannel] error:", err);
    return false;
  }
}

/**
 * ã‚¹ãƒ¬ãƒƒãƒ‰ã®æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†’é ­ã«ç¦æ­¢çµµæ–‡å­—(ğŸˆ² or ğŸš«)ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
 * å«ã¾ã‚Œã¦ã„ã‚Œã°trueã€ãã†ã§ãªã‘ã‚Œã°falseã‚’è¿”ã™
 */
function isRestrictedThread(post: any, postsObj: Record<string, any>): boolean {
  // ã‚¹ãƒ¬ãƒƒãƒ‰ã®ãƒ«ãƒ¼ãƒˆãƒã‚¹ãƒˆã‚’å–å¾—
  const rootId = post.root_id || post.id;
  const rootPost = postsObj[rootId];
  
  if (!rootPost) {
    return false;
  }
  
  // ãƒ«ãƒ¼ãƒˆãƒã‚¹ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†’é ­ã«ç¦æ­¢çµµæ–‡å­—ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
  const message = rootPost.message || "";
  return message.trimStart().startsWith("ğŸˆ²") || message.trimStart().startsWith("ğŸš«");
}

/** Mattermost ã«æŠ•ç¨¿ã™ã‚‹ (æŠ•ç¨¿å…ˆãƒãƒ£ãƒ³ãƒãƒ«ã¯ MATTERMOST_SUMMARY_CHANNEL) */
async function postToMattermost(message: string): Promise<void> {
  if (!MATTERMOST_SUMMARY_CHANNEL) {
    console.warn("MATTERMOST_SUMMARY_CHANNEL is not set. Skipping post.");
    return;
  }

  const url = `${MATTERMOST_URL}/api/v4/posts`;
  const body = {
    channel_id: MATTERMOST_SUMMARY_CHANNEL,
    message,
  };
  const res = await fetch(url, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${MATTERMOST_BOT_TOKEN}`,
      Accept: "application/json",
      "Content-Type": "application/json",
    },
    body: JSON.stringify(body),
  });
  if (!res.ok) {
    const errText = await res.text();
    console.error("[postToMattermost] failed", errText);
    throw new Error(`Failed to post summary: ${errText}`);
  }
}

// ãƒ¦ãƒ¼ã‚¶IDâ†’username ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨
const userNameCache: Record<string, string> = {}

/** æŒ‡å®šãƒ¦ãƒ¼ã‚¶IDã® username ã‚’å–å¾— (ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¾¼ã¿) */
async function fetchUserName(userId: string): Promise<string> {
  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ãªã‚‰å†ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãªã„
  if (userNameCache[userId]) {
    return userNameCache[userId]
  }

  const url = `${MATTERMOST_URL}/api/v4/users/${userId}`
  const res = await fetch(url, {
    headers: {
      Authorization: `Bearer ${MATTERMOST_BOT_TOKEN}`,
      Accept: 'application/json',
    }
  })
  if (!res.ok) {
    console.error(`[fetchUserName] Failed to fetch user data for ${userId}`, await res.text())
    // ãƒ¦ãƒ¼ã‚¶å–å¾—å¤±æ•—ã—ãŸã‚‰ "unknown" ã¨ã—ã¦è¿”ã™
    userNameCache[userId] = "unknown"
    return "unknown"
  }

  const data = await res.json()
  // data.username ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
  userNameCache[userId] = data.username || "unknown"

  return userNameCache[userId]
}

/**
 * æŒ‡å®šã—ãŸ channelId å†…ã®æŠ•ç¨¿ã‚’ startUTCï½endUTC ã®é–“ã§å–å¾—ã—ã€
 * å„æŠ•ç¨¿ã§æ¤œå‡ºã—ãŸå¤–éƒ¨URLã® OGP æƒ…å ±ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ¬æ–‡ã«è¿½è¨˜ã—ã¤ã¤ã€
 * ã•ã‚‰ã«ã€Œèª°ãŒã©ã‚“ãªçµµæ–‡å­—ã‚’ã¤ã‘ãŸã‹ã€ã‚’å–å¾—ã—ã¦æ ¼ç´ã—ã¾ã™ã€‚
 */
export async function fetchPostsInRange(
  channelId: string,
  startUTC: number,
  endUTC: number
): Promise<any[]> {
  try {
    console.log(`Fetching posts in range for channel: ${channelId}, from ${new Date(startUTC).toISOString()} to ${new Date(endUTC).toISOString()}`);
    
    // ã¾ãšã€ãƒãƒ£ãƒ³ãƒãƒ«ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    const isRestricted = await isRestrictedChannel(channelId);
    if (isRestricted) {
      console.log(`Channel ${channelId} is restricted. Skipping.`);
      return [];
    }
    
    const url = `${MATTERMOST_URL}/api/v4/channels/${channelId}/posts?per_page=200`;
    const res = await fetch(url, {
      headers: {
        Authorization: `Bearer ${MATTERMOST_BOT_TOKEN}`,
        Accept: "application/json",
      },
    });
    if (!res.ok) {
      console.error("[fetchPostsInRange] failed", await res.text());
      return [];
    }

    const data = await res.json();
    if (!data.posts) {
      console.log("No posts found in response data.");
      return [];
    }

    const postIds: string[] = data.order || [];
    const postsObj = data.posts;

    // ç¯„å›²å†… (startUTC <= create_at < endUTC) ã§ãƒ•ã‚£ãƒ«ã‚¿
    const result: any[] = [];
    console.log(`Total posts in channel: ${postIds.length}`);
    let inRangeCount = 0;
    let restrictedCount = 0;
    
    for (const pid of postIds) {
      const p = postsObj[pid];
      if (p && p.create_at >= startUTC && p.create_at < endUTC) {
        inRangeCount++;
        console.log(`Processing post: ${p.id} (created at ${new Date(p.create_at).toISOString()})`);
        
        // åˆ¶é™ã•ã‚ŒãŸã‚¹ãƒ¬ãƒƒãƒ‰ã«å±ã™ã‚‹æŠ•ç¨¿ã¯ã‚¹ã‚­ãƒƒãƒ—
        if (isRestrictedThread(p, postsObj)) {
          console.log(`Post ${p.id} is in a restricted thread. Skipping.`);
          restrictedCount++;
          continue;
        }

        // ----- è¿½è¨˜: å„æŠ•ç¨¿ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—ã—ã€p.message ã®æœ«å°¾ã«è¿½è¨˜ -----
        try {
          console.log(`Fetching reactions for post: ${p.id}`);
          const reactions = await getReactions(p.id);
          if (reactions.length > 0) {
            // ãã‚Œãã‚Œã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ãƒ¦ãƒ¼ã‚¶åã‚’å–å¾—ã—ã¦æ–‡å­—åˆ—ã‚’ä½œæˆ
            const reactionStrings: string[] = [];
            for (const r of reactions) {
              const userName = await fetchUserName(r.user_id);
              reactionStrings.push(`:${r.emoji_name}: by @${userName}`);
            }
            p.message += `\n\n---\nReactions:\n${reactionStrings.join("\n")}`;
          }
        } catch (err) {
          console.log(`No reactions for post ${p.id}`, err);
        }

        result.push(p);
      }
    }

    // å¤ã„â†’æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ
    result.sort((a, b) => a.create_at - b.create_at);
    console.log(`Posts summary: ${inRangeCount} in range, ${restrictedCount} restricted, ${result.length} included in results`);
    return result;
  } catch (err) {
    console.error("[fetchPostsInRange] error:", err);
    return [];
  }
}

/** éŸ³å£°ç”Ÿæˆã‚¸ãƒ§ãƒ–ã‚’é€ä¿¡ã™ã‚‹ */
async function submitAudioJob(script: string, language: 'ja-JP' | 'en-US', engine: string = 'gemini'): Promise<{ job_id: string; events_url: string } | null> {
  try {
    let requestBody: any;
    let apiUrl: string;
    
    if (engine === 'voicevox') {
      console.log('Using VoiceVox engine for Zundamon');
      // VoiceVox APIã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ ï¼ˆä¾‹: /audio_query ã‚„ /synthesis ãªã©ï¼‰
      apiUrl = 'https://voicevox-zunda-597706528463.asia-northeast1.run.app/submit-audio-job';
      requestBody = {
        script: script,
        engine: 'voicevox',
        speaker: 3, // ãšã‚“ã ã‚‚ã‚“ã®ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼IDï¼ˆé€šå¸¸ã¯3ï¼‰
        speedScale: 1.15, // è©±é€Ÿï¼ˆ1.0ãŒæ¨™æº–ã€1.15ã§å…ƒæ°—ã‚ˆãé€Ÿã‚ï¼‰
        pitchScale: 0.04, // éŸ³é«˜ï¼ˆ0ãŒæ¨™æº–ã€0.04ã§å°‘ã—é«˜ã‚ã§æ˜ã‚‹ã„å£°ï¼‰
        intonationScale: 1.5, // æŠ‘æšï¼ˆ1ãŒæ¨™æº–ã€1.5ã§è¡¨ç¾è±Šã‹ã«ï¼‰
        volumeScale: 1 // éŸ³é‡ï¼ˆ1ãŒæ¨™æº–ï¼‰
      };
    } else {
      apiUrl = 'https://submit-audio-job-oxjztisiiq-an.a.run.app';
      const [voice1, voice2] = getRandomVoices();
      console.log(`Selected voices: ${voice1}, ${voice2}`);
      requestBody = {
        script: script,
        speakers: ["Speaker 1", "Speaker 2"],
        voices: [voice1, voice2],
        prompt: language === 'ja-JP' ? "Japanese tech podcaster speaking very fast and casually" : "English tech podcaster speaking enthusiastically and casually",
        model: "gemini-2.5-pro-preview-tts",
        language: language
      };
    }
    
    console.log(`Submitting audio job to ${apiUrl}`);
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody),
    });
    
    if (!response.ok) {
      console.error('[submitAudioJob] API call failed:', await response.text());
      return null;
    }
    
    return await response.json();
  } catch (err) {
    console.error('[submitAudioJob] error:', err);
    return null;
  }
}

/** ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã™ã‚‹ */
function splitTextForVoiceVox(text: string, maxLength: number = 500): string[] {
  const sentences = text.split(/(?<=[ã€‚ï¼ï¼Ÿ\n])/);
  const chunks: string[] = [];
  let currentChunk = '';
  
  for (const sentence of sentences) {
    if (currentChunk.length + sentence.length > maxLength && currentChunk.length > 0) {
      chunks.push(currentChunk.trim());
      currentChunk = sentence;
    } else {
      currentChunk += sentence;
    }
  }
  
  if (currentChunk.trim()) {
    chunks.push(currentChunk.trim());
  }
  
  return chunks;
}

/** WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è§£æã—ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— */
function extractAudioData(buffer: ArrayBuffer): { data: Uint8Array; sampleRate: number; channels: number; bitsPerSample: number } | null {
  try {
    const view = new DataView(buffer);
    
    // WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®æ¤œè¨¼
    const riff = String.fromCharCode(view.getUint8(0), view.getUint8(1), view.getUint8(2), view.getUint8(3));
    if (riff !== 'RIFF') {
      console.error('Not a valid WAV file - missing RIFF header');
      return null;
    }
    
    // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæƒ…å ±ã‚’å–å¾—
    const channels = view.getUint16(22, true);
    const sampleRate = view.getUint32(24, true);
    const bitsPerSample = view.getUint16(34, true);
    
    // dataãƒãƒ£ãƒ³ã‚¯ã‚’æ¢ã™
    let offset = 12;
    while (offset < buffer.byteLength - 8) {
      const chunkId = String.fromCharCode(
        view.getUint8(offset),
        view.getUint8(offset + 1),
        view.getUint8(offset + 2),
        view.getUint8(offset + 3)
      );
      const chunkSize = view.getUint32(offset + 4, true);
      
      if (chunkId === 'data') {
        const dataStart = offset + 8;
        const data = new Uint8Array(buffer, dataStart, chunkSize);
        return { data, sampleRate, channels, bitsPerSample };
      }
      
      offset += 8 + chunkSize;
      // å¥‡æ•°ã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã®å ´åˆã¯1ãƒã‚¤ãƒˆã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãŒã‚ã‚‹
      if (chunkSize % 2 === 1) {
        offset += 1;
      }
    }
    
    console.error('Data chunk not found in WAV file');
    return null;
  } catch (err) {
    console.error('Error parsing WAV file:', err);
    return null;
  }
}

/** è¤‡æ•°ã®WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ã‚¸ */
function mergeWavFiles(buffers: ArrayBuffer[]): ArrayBuffer {
  if (buffers.length === 0) return new ArrayBuffer(0);
  if (buffers.length === 1) return buffers[0];
  
  // å„ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
  const audioDataList: { data: Uint8Array; sampleRate: number; channels: number; bitsPerSample: number }[] = [];
  
  for (let i = 0; i < buffers.length; i++) {
    const extracted = extractAudioData(buffers[i]);
    if (!extracted) {
      console.error(`Failed to extract audio data from buffer ${i}`);
      continue;
    }
    audioDataList.push(extracted);
  }
  
  if (audioDataList.length === 0) {
    console.error('No valid audio data found');
    return new ArrayBuffer(0);
  }
  
  // æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’åŸºæº–ã«ã™ã‚‹
  const { sampleRate, channels, bitsPerSample } = audioDataList[0];
  
  // å…¨ã¦ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
  let totalDataSize = 0;
  for (const audio of audioDataList) {
    totalDataSize += audio.data.length;
  }
  
  // æ–°ã—ã„WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
  const headerSize = 44;
  const fileSize = headerSize + totalDataSize;
  const outputBuffer = new ArrayBuffer(fileSize);
  const view = new DataView(outputBuffer);
  const outputArray = new Uint8Array(outputBuffer);
  
  // RIFFãƒ˜ãƒƒãƒ€ãƒ¼
  outputArray[0] = 0x52; // 'R'
  outputArray[1] = 0x49; // 'I'
  outputArray[2] = 0x46; // 'F'
  outputArray[3] = 0x46; // 'F'
  view.setUint32(4, fileSize - 8, true);
  outputArray[8] = 0x57; // 'W'
  outputArray[9] = 0x41; // 'A'
  outputArray[10] = 0x56; // 'V'
  outputArray[11] = 0x45; // 'E'
  
  // fmtãƒãƒ£ãƒ³ã‚¯
  outputArray[12] = 0x66; // 'f'
  outputArray[13] = 0x6D; // 'm'
  outputArray[14] = 0x74; // 't'
  outputArray[15] = 0x20; // ' '
  view.setUint32(16, 16, true); // fmtãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º
  view.setUint16(20, 1, true); // PCM
  view.setUint16(22, channels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * channels * bitsPerSample / 8, true);
  view.setUint16(32, channels * bitsPerSample / 8, true);
  view.setUint16(34, bitsPerSample, true);
  
  // dataãƒãƒ£ãƒ³ã‚¯
  outputArray[36] = 0x64; // 'd'
  outputArray[37] = 0x61; // 'a'
  outputArray[38] = 0x74; // 't'
  outputArray[39] = 0x61; // 'a'
  view.setUint32(40, totalDataSize, true);
  
  // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
  let offset = headerSize;
  for (const audio of audioDataList) {
    outputArray.set(audio.data, offset);
    offset += audio.data.length;
  }
  
  console.log(`Merged ${audioDataList.length} WAV files, total size: ${fileSize} bytes`);
  return outputBuffer;
}

/** VoiceVoxã‚’ä½¿ã£ã¦éŸ³å£°ã‚’ç›´æ¥ç”Ÿæˆã™ã‚‹ï¼ˆé•·ã„ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œï¼‰ */
async function synthesizeWithVoiceVox(script: string): Promise<string | null> {
  try {
    console.log('Synthesizing with VoiceVox...');
    console.log('Total script length:', script.length);
    
    // ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
    const chunks = splitTextForVoiceVox(script);
    console.log(`Split into ${chunks.length} chunks`);
    
    // ä¸¦åˆ—å‡¦ç†ã®é–‹å§‹ã‚’ã‚ãšã‹ã«ãšã‚‰ã™
    const audioPromises = chunks.map(async (chunk, i) => {
      // å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å°‘ã—ãšã¤é…å»¶ã•ã›ã¦é–‹å§‹
      await new Promise(resolve => setTimeout(resolve, i * 50));
      console.log(`Processing chunk ${i + 1}/${chunks.length}, length: ${chunk.length}`);
      
      try {
        // Step 1: Create audio query
        const audioQueryUrl = `https://voicevox-zunda-597706528463.asia-northeast1.run.app/audio_query?text=${encodeURIComponent(chunk)}&speaker=3`;
        const queryResponse = await fetch(audioQueryUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
        });
        
        if (!queryResponse.ok) {
          console.error(`[synthesizeWithVoiceVox] Audio query failed for chunk ${i + 1}:`, await queryResponse.text());
          return null;
        }
        
        const audioQuery = await queryResponse.json();
        
        // ãšã‚“ã ã‚‚ã‚“ã‚‰ã—ã„å…ƒæ°—ãªå£°ã«ãªã‚‹ã‚ˆã†ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´
        audioQuery.speedScale = 1.15;      // è©±é€Ÿã‚’å°‘ã—é€Ÿã‚ã«
        audioQuery.pitchScale = 0.04;      // éŸ³é«˜ã‚’å°‘ã—é«˜ã‚ã«ï¼ˆæ˜ã‚‹ã„å£°ï¼‰
        audioQuery.intonationScale = 1.5;  // æŠ‘æšã‚’è±Šã‹ã«
        audioQuery.volumeScale = 1;        // éŸ³é‡ã¯æ¨™æº–
        
        // Step 2: Synthesize audio
        const synthesisUrl = `https://voicevox-zunda-597706528463.asia-northeast1.run.app/synthesis?speaker=3`;
        const synthesisResponse = await fetch(synthesisUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(audioQuery),
        });
        
        if (!synthesisResponse.ok) {
          console.error(`[synthesizeWithVoiceVox] Synthesis failed for chunk ${i + 1}:`, await synthesisResponse.text());
          return null;
        }
        
        // Get audio data as ArrayBuffer
        const audioBuffer = await synthesisResponse.arrayBuffer();
        console.log(`Chunk ${i + 1} synthesized, size: ${audioBuffer.byteLength}`);
        
        // ãƒãƒ¼ã‚¸å‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãªã„ - ãƒ¡ãƒ¢ãƒªã«ä¿æŒã™ã‚‹ã ã‘
        return { index: i, buffer: audioBuffer };
      } catch (err) {
        console.error(`[synthesizeWithVoiceVox] Error processing chunk ${i + 1}:`, err);
        return null;
      }
    });
    
    // å…¨ã¦ã®ä¸¦åˆ—å‡¦ç†ãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã¤
    const results = await Promise.all(audioPromises);
    
    // æˆåŠŸã—ãŸçµæœã‚’é †ç•ªã«ä¸¦ã¹æ›¿ãˆ
    const audioBuffers: ArrayBuffer[] = [];
    for (const result of results) {
      if (result && result.buffer) {
        audioBuffers[result.index] = result.buffer;
      }
    }
    
    // null ã‚’é™¤å»
    const validBuffers = audioBuffers.filter(buffer => buffer != null);
    
    if (validBuffers.length === 0) {
      console.error('[synthesizeWithVoiceVox] No audio chunks were successfully synthesized');
      return null;
    }
    
    console.log(`Successfully synthesized ${validBuffers.length} audio chunks`);
    console.log('Merging audio chunks...');
    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ã‚¸
    const mergedBuffer = mergeWavFiles(validBuffers);
    console.log('Merged audio size:', mergedBuffer.byteLength);
    
    // ãƒãƒ¼ã‚¸ã—ãŸéŸ³å£°ã‚‚Storageã«ä¿å­˜
    const timestamp = new Date().getTime();
    const mergedFileName = `zundamon_merged_${timestamp}.wav`;
    const mergedFilePath = `voice/${mergedFileName}`;
    
    const { data: mergedUploadData, error: mergedUploadError } = await supabase.storage
      .from('audio')
      .upload(mergedFilePath, mergedBuffer, {
        contentType: 'audio/wav',
        upsert: false
      });
      
    if (mergedUploadError) {
      console.error('Failed to upload merged audio to storage:', mergedUploadError);
      // ã‚¨ãƒ©ãƒ¼ã§ã‚‚base64ã¨ã—ã¦è¿”ã™
      const base64 = btoa(String.fromCharCode(...new Uint8Array(mergedBuffer)));
      return `data:audio/wav;base64,${base64}`;
    }
    
    // ãƒ‘ãƒ–ãƒªãƒƒã‚¯URLã‚’å–å¾—
    const { data: { publicUrl: mergedPublicUrl } } = supabase.storage
      .from('audio')
      .getPublicUrl(mergedFilePath);
      
    console.log(`Merged audio uploaded to: ${mergedPublicUrl}`);
    
    return mergedPublicUrl;
  } catch (err) {
    console.error('[synthesizeWithVoiceVox] error:', err);
    return null;
  }
}

/** SSEã‚’ä½¿ã£ã¦éŸ³å£°ç”Ÿæˆã‚¸ãƒ§ãƒ–ã®å®Œäº†ã‚’å¾…ã¤ */
async function waitForAudioCompletion(eventsUrl: string): Promise<string | null> {
  try {
    console.log('Connecting to SSE:', eventsUrl);
    
    // Denoç’°å¢ƒã§SSEã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã€fetchã®streamã‚’ä½¿ç”¨
    const response = await fetch(eventsUrl);
    if (!response.ok) {
      console.error('[waitForAudioCompletion] SSE connection failed');
      return null;
    }
    
    const reader = response.body?.getReader();
    if (!reader) {
      console.error('[waitForAudioCompletion] No reader available');
      return null;
    }
    
    const decoder = new TextDecoder();
    let buffer = '';
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      buffer += decoder.decode(value, { stream: true });
      const lines = buffer.split('\n');
      buffer = lines.pop() || '';
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = JSON.parse(line.slice(6));
          console.log('SSE update:', data);
          
          // waitingçŠ¶æ…‹ã§ã‚‚URLãŒã‚ã‚Œã°è¿”ã™
          if (data.url && (data.status === 'waiting' || data.status === 'completed')) {
            reader.releaseLock();
            return data.url;
          } else if (data.status === 'error' || data.status === 'timeout') {
            reader.releaseLock();
            console.error('Audio generation failed:', data);
            return null;
          }
        }
      }
    }
    
    reader.releaseLock();
    console.error('SSE stream ended without completion');
    return null;
  } catch (err) {
    console.error('[waitForAudioCompletion] error:', err);
    return null;
  }
}